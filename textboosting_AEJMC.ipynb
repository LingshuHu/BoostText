{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lingshu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Import Python Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "## Libraries for Bert\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bert Model. \n",
    "## Codes adopted from: https://towardsdatascience.com/build-a-bert-sci-kit-transformer-59d60ddd54a5\n",
    "\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_tokenizer,\n",
    "            bert_model,\n",
    "            max_length: int = 512,\n",
    "            embedding_func: Optional[Callable[[torch.tensor], torch.tensor]] = None,\n",
    "    ):\n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.model = bert_model\n",
    "        self.model.eval()\n",
    "        self.max_length = max_length\n",
    "        self.embedding_func = embedding_func\n",
    "\n",
    "        if self.embedding_func is None:\n",
    "            self.embedding_func = lambda x: x[0][:, 0, :].squeeze()\n",
    "\n",
    "    def _tokenize(self, text: str) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        # Tokenize the text with the provided tokenizer\n",
    "        tokenized_text = self.tokenizer.encode_plus(text,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    max_length=self.max_length\n",
    "                                                    )[\"input_ids\"]\n",
    "        # Create an attention mask telling BERT to use all words\n",
    "        attention_mask = [1] * len(tokenized_text)\n",
    "        # bert takes in a batch so we need to unsqueeze the rows\n",
    "        return (\n",
    "            torch.tensor(tokenized_text).unsqueeze(0),\n",
    "            torch.tensor(attention_mask).unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    def _tokenize_and_predict(self, text: str) -> torch.tensor:\n",
    "        tokenized, attention_mask = self._tokenize(text)\n",
    "        embeddings = self.model(tokenized, attention_mask)\n",
    "        return self.embedding_func(embeddings)\n",
    "\n",
    "    def transform(self, text: List[str]):\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            return torch.stack([self._tokenize_and_predict(string) for string in text])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"No fitting necessary so we just return ourselves\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "bert_transformer = BertTransformer(tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean text\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def text_process(text):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(text))\n",
    "    document = re.sub(r'https?:\\S+|http?:\\S', '', document)\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    return(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define K-Ford Model\n",
    "\n",
    "# need these:\n",
    "cv = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
    "#lgt = LogisticRegression(random_state=111)\n",
    "sm = SMOTE(random_state = 111)\n",
    "\n",
    "class kford_model():\n",
    "    def __init__(self, X, y, model):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.model = model\n",
    "        \n",
    "    def results(self, SMOTE = False):\n",
    "        all_models = []\n",
    "        all_x_train = []\n",
    "        all_x_test = []\n",
    "        all_y_train = []\n",
    "        all_y_test = []\n",
    "        all_y_pred = []\n",
    "        all_scores_train = []\n",
    "        all_scores_test = []\n",
    "        for train_index, test_index in cv.split(X):    \n",
    "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
    "            if SMOTE:\n",
    "                X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "            #X_test_sm, y_test_sm = sm.fit_sample(X_test, y_test)\n",
    "            m = self.model.fit(X_train, y_train)\n",
    "            all_models.append(m)\n",
    "            all_x_train.append(X_train)\n",
    "            all_x_test.append(X_test)\n",
    "            all_y_train.append(y_train)\n",
    "            all_y_test.append(y_test)\n",
    "            all_y_pred.append(m.predict(X_test))\n",
    "            all_scores_train.append(m.score(X_train, y_train))\n",
    "            all_scores_test.append(m.score(X_test, y_test))\n",
    "        return(all_models, all_x_train, all_x_test, all_y_train, all_y_test, \n",
    "               all_y_pred, all_scores_train, all_scores_test)\n",
    "    \n",
    "    def show_results(self, SMOTE = False, return_results = False):\n",
    "        all_models, all_x_train, all_x_test, all_y_train, all_y_test, all_y_pred, all_scores_train, all_scores_test = self.results(SMOTE = SMOTE)\n",
    "        all_y_test_flat = [i for lst in all_y_test for i in lst ]\n",
    "        all_y_pred_flat = [i for lst in all_y_pred for i in lst ]\n",
    "        print(\"All test scores: \", all_scores_test)\n",
    "        print(\"Mean train accuracy: \", np.mean(all_scores_train))\n",
    "        print(\"Mean test accuracy: \", np.mean(all_scores_test))\n",
    "        kford_matrix = confusion_matrix(all_y_test_flat, all_y_pred_flat)\n",
    "        \n",
    "        fig, ax = plot_confusion_matrix(conf_mat=kford_matrix,show_absolute=True,show_normed=True,\n",
    "                                        colorbar=False,figsize = (3,3),hide_spines = True)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        if return_results:\n",
    "            return(all_models, all_x_train, all_x_test, all_y_train, all_y_test, \n",
    "                   all_y_pred, all_scores_train, all_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boosting(base_model, boost_model, itera, X_train, y_train, X_test, y_test, loc=\"center right\"):\n",
    "\n",
    "    score1 = base_model.score(X_train, y_train)\n",
    "    score2 = base_model.score(X_test, y_test)\n",
    "    base_train = np.full((itera,), score1)\n",
    "    base_test = np.full((itera,), score2)\n",
    "\n",
    "    boost_train = np.zeros((itera,))\n",
    "    for i, y_pred in enumerate(boost_model.staged_predict(X_train)):\n",
    "        boost_train[i] = accuracy_score(y_true = y_train, y_pred = y_pred)\n",
    "\n",
    "    boost_test = np.zeros((itera,))\n",
    "    for i, y_pred in enumerate(boost_model.staged_predict(X_test)):\n",
    "        boost_test[i] = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.plot(np.arange(itera) + 1, boost_train,\n",
    "           label = \"AdaBoost Train Accuracy\",\n",
    "           color = \"blue\")\n",
    "\n",
    "    ax.plot(np.arange(itera) + 1, boost_test,\n",
    "           label = \"AdaBoost Test Accuracy\",\n",
    "           color = \"red\")\n",
    "\n",
    "    ax.plot(np.arange(itera) + 1, base_train,\n",
    "           label = \"BaseModel Train Accuracy\",\n",
    "           color = \"green\", linestyle = \"dashed\")\n",
    "\n",
    "    ax.plot(np.arange(itera) + 1, base_test,\n",
    "           label = \"BaseModel Test Accuracy\",\n",
    "           color = \"black\", linestyle = \"dashed\")\n",
    "\n",
    "    #ax.title('Training and test accuracy of boosting and base model')\n",
    "    ax.legend(loc=loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model):\n",
    "    \n",
    "    print(\"train accuracy: \", model.score(X_train, y_train))\n",
    "    print(\"test accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=matrix, show_absolute=True, show_normed=True, colorbar=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read imdb dataset\n",
    "df = pd.read_csv(\"./imdb-review-dataset/imdb_master.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read NYT dataset\n",
    "df = pd.read_csv(\"data/training_text_no_other_1980-2019.csv\", encoding = \"ISO-8859-1\")\n",
    "df = df[df['system']!='o']\n",
    "df = df.rename(columns={\"system\": \"label\", \"text\": \"review\"})\n",
    "#df = shuffle(df, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['label']== 'p']\n",
    "df2 = df[df['label']== 's']\n",
    "df3 = df[df['label']== 'c']\n",
    "df4 = df[df['label']== 'b']\n",
    "df1 = df1.sample(400, replace=False, random_state=111)\n",
    "df2 = df2.sample(300, replace=False, random_state=111)\n",
    "df3 = df3.sample(200, replace=False, random_state=111)\n",
    "df4 = df4.sample(100, replace=False, random_state=111)\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "df = shuffle(df, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    400\n",
       "s    300\n",
       "c    200\n",
       "b    100\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['system']!='o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select imbalanced data\n",
    "dfn = df[df['label']== 'neg']\n",
    "dfp = df[df['label']== 'pos']\n",
    "dfp = dfp.sample(800, replace=False, random_state=111)\n",
    "dfn = dfn.sample(200, replace=False, random_state=111)\n",
    "df = pd.concat([dfn, dfp])\n",
    "df = shuffle(df, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i in range(0, len(df.review.values)):\n",
    "    document = text_process(df.review.values[i])\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFID vector\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=300, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = tfidfconverter.fit_transform(documents).toarray()\n",
    "y = df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "## Bert vector\n",
    "X = bert_transformer.transform(documents).numpy()\n",
    "y = df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reduce Bert vector dimension\n",
    "pca = PCA(n_components=300, random_state = 111)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test scores:  [0.79, 0.78, 0.82, 0.86, 0.76, 0.74, 0.76, 0.77, 0.67, 0.79]\n",
      "Mean train accuracy:  0.9083174365276822\n",
      "Mean test accuracy:  0.774\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state=111)\n",
    "\n",
    "fm = kford_model(X, y, lg)\n",
    "rs = fm.show_results(SMOTE = True, return_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test scores:  [0.74, 0.81, 0.82, 0.86, 0.77, 0.76, 0.77, 0.76, 0.69, 0.82]\n",
      "Mean train accuracy:  0.8597777777777779\n",
      "Mean test accuracy:  0.78\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state=111)\n",
    "\n",
    "fm = kford_model(X, y, lg)\n",
    "rs = fm.show_results(SMOTE = False, return_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test scores:  [0.64, 0.58, 0.62, 0.57, 0.62, 0.57, 0.67, 0.62, 0.63, 0.59]\n",
      "Mean train accuracy:  1.0\n",
      "Mean test accuracy:  0.611\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(random_state=111)\n",
    "\n",
    "fm = kford_model(X, y, dt)\n",
    "rs = fm.show_results(SMOTE = True, return_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test scores:  [0.77, 0.79, 0.76, 0.76, 0.73, 0.75, 0.79, 0.76, 0.75, 0.73]\n",
      "Mean train accuracy:  0.8459999999999999\n",
      "Mean test accuracy:  0.759\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 32s, sys: 12.3 s, total: 15min 44s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blg = AdaBoostClassifier(LogisticRegression(random_state=111),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         learning_rate=1, \n",
    "                         n_estimators=2000,\n",
    "                         random_state=111)\n",
    "\n",
    "bfm = kford_model(X, y, blg)\n",
    "brs = bfm.show_results(SMOTE = False, return_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test scores:  [0.63, 0.62, 0.65, 0.58, 0.57, 0.63, 0.64, 0.57, 0.65, 0.57]\n",
      "Mean train accuracy:  1.0\n",
      "Mean test accuracy:  0.6110000000000001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.57 s, sys: 144 ms, total: 8.72 s\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bdt = AdaBoostClassifier(tree.DecisionTreeClassifier(random_state=111),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         learning_rate=1, \n",
    "                         n_estimators=2000,\n",
    "                         random_state=111)\n",
    "\n",
    "bfm = kford_model(X, y, bdt)\n",
    "brs = bfm.show_results(SMOTE = True, return_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_kford_data(kford_results, which = 1):\n",
    "    km = kford_results[0][which]\n",
    "    X_train = kford_results[1][which]\n",
    "    X_test = kford_results[2][which]\n",
    "    y_train = kford_results[3][which]\n",
    "    y_test = kford_results[4][which]\n",
    "    return(km, X_train, X_test, y_train, y_test)\n",
    "\n",
    "km, X_train, X_test, y_train, y_test = get_kford_data(kford_results = brs, which = 1)\n",
    "\n",
    "plot_boosting(lg, km, 2000, X_train, y_train, X_test, y_test, \"lower right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
